{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL-Faql-Cj7V"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "In this assignment you will implement ResNet18.\n",
        "Read the comments carefully and insert your code where you see: <br><br><b>##### START OF YOUR CODE #####</b><br><br><b>##### END OF YOUR CODE #####</b><br><br>or for the inline codes you will see<br><br><b>##### INSERT YOUR CODE HERE #####</b>\n",
        "\n",
        "### The architecture of ResNet-18 is shown in the table.\n",
        "First, we will define a convolutional block with skip connection. Then, create the model using these blocks.<br><br>\n",
        "<img src=\"https://www.researchgate.net/profile/Paolo-Napoletano/publication/322476121/figure/tbl1/AS:668726449946625@1536448218498/ResNet-18-Architecture.png\" width=\"500\" alt=\"ResNet18 Architecture\">\n",
        "\n",
        "<br><sup>Image ref: Napoletano, Paolo, et al. ‘Anomaly Detection in Nanofibrous Materials by CNN-Based Self-Similarity’. Sensors (Basel, Switzerland), vol. 18, 01 2018, https://doi.org10.3390/s18010209.</sup>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X38vEzbBWFNt"
      },
      "source": [
        "#### I. ConvBlock\n",
        "<img src=\"https://www.researchgate.net/publication/334301817/figure/fig3/AS:778452965801986@1562609058538/Residual-block-of-ResNet18-with-a-1-1-convolutional-mapping-based-residual-unit-and.png\"><br>\n",
        "ResNet consists of convolutional (a) and identity (b) blocks. For ResNet-18 we will only use convolutional blocks. In this step you will write a class for convolutional block. The arguments will be:\n",
        "\n",
        "* ch_in: input channels\n",
        "* ch_out: output channels\n",
        "* s: strides\n",
        "* act: activation function\n",
        "\n",
        "The options for activation function are \"relu\", \"leaky_relu\" and \"gelu\".\n",
        "<br><br>\n",
        "<sup>Image ref: Owais, Muhammad, et al. ‘Artificial Intelligence-Based Classification of Multiple Gastrointestinal Diseases Using Endoscopy Videos for Clinical Diagnosis’. Journal of Clinical Medicine, vol. 8, 07 2019, p. 986, https://doi.org10.3390/jcm8070986.</sup>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "w4zlwn3H8ZUR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out, s, act):\n",
        "      super(ConvBlock,self).__init__()\n",
        "      # Initialize layers\n",
        "      ##### START OF YOUR CODE #####\n",
        "      activations = {'relu': torch.nn.ReLU(),\n",
        "                     'leaky_relu': torch.nn.LeakyReLU(),\n",
        "                     'gelu': torch.nn.GELU()}\n",
        "      self.conv1 = nn.Conv2d(in_channels = ch_in, out_channels = ch_out, kernel_size = (1, 1), stride = (s, s))\n",
        "      self.batch1 =  nn.BatchNorm2d(num_features  = ch_out)\n",
        "\n",
        "      self.conv2 = nn.Conv2d(in_channels = ch_in, out_channels = ch_in, kernel_size = (3, 3), stride = (s, s), padding = (1, 1))\n",
        "      self.batch2 = nn.BatchNorm2d(num_features  = ch_in)\n",
        "      self.act1 = activations[act]\n",
        "      self.conv3 = nn.Conv2d(in_channels = ch_in, out_channels = ch_out, kernel_size = (3, 3), stride = (1, 1), padding = (1, 1))\n",
        "      self.batch3 = nn.BatchNorm2d(num_features  = ch_out)\n",
        "      self.act2 = activations[act]\n",
        "\n",
        "      ##### END OF YOUR CODE #####\n",
        "\n",
        "    def forward(self, X):\n",
        "      ##### START OF YOUR CODE #####\n",
        "\n",
        "      fx = self.conv2(X)\n",
        "      fx = self.batch2(fx)\n",
        "      fx = self.act1(fx)\n",
        "      fx = self.conv3(fx)\n",
        "      fx = self.batch3(fx)\n",
        "      \n",
        "      hx = self.conv1(X)\n",
        "      hx = self.batch1(hx)\n",
        "           \n",
        "      X = hx + fx\n",
        "      X = self.act2(X)\n",
        "      ##### END OF YOUR CODE #####\n",
        "      return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS8xDz-ncs1F"
      },
      "source": [
        "#### II. ResNet18 class\n",
        "Use the ConvBlock class to create ResNet18.\n",
        "* Add batch normalization and activation function after the first conv layer as well.\n",
        "* Examine the output sizes in the table above and use paddings and strides where needed.\n",
        "* Pytorch doesn't have a global average pooling layer. Instead you should reshape the image as (B, C, W*H) and calculate the mean of the last dimension without keeping the dims. It will result in a tensor of (B, C)\n",
        "* Fully connected layer should be 512 x 1 as we have only 2 classes and we will use sigmoid function as the final activation layer.\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Paolo-Napoletano/publication/322476121/figure/tbl1/AS:668726449946625@1536448218498/ResNet-18-Architecture.png\" width=\"500\" alt=\"ResNet18 Architecture\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Npd7BHRsdFqt"
      },
      "outputs": [],
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, act, drop_rate):\n",
        "      super(ResNet18, self).__init__()\n",
        "      # Initialize layers\n",
        "      ##### START OF YOUR CODE #####\n",
        "      # input: 16, 1, 256, 256 (batch size, channel, height, width) or 256 x 256 x 1\n",
        "      activations = {'relu': torch.nn.ReLU(),\n",
        "                     'leaky_relu': torch.nn.LeakyReLU(),\n",
        "                     'gelu': torch.nn.GELU()}\n",
        "\n",
        "      self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = (7, 7), stride = (2, 2), padding = (3, 3)) # learnable parameters: 7*7*1*64 + 64 (bias) = 3200\n",
        "      self.batch1 = nn.BatchNorm2d(num_features  = 64)\n",
        "      self.act1 = activations[act]\n",
        "\n",
        "      self.maxpool1 = nn.MaxPool2d(3, stride= 2, padding = (1, 1))\n",
        "      self.conv21_x = ConvBlock(ch_in = 64, ch_out = 64, s = 1, act = act)\n",
        "      self.conv22_x = ConvBlock(ch_in = 64, ch_out = 64, s = 1, act = act)\n",
        "\n",
        "      self.conv31_x = ConvBlock(ch_in = 64, ch_out = 64, s = 2, act = act)\n",
        "      self.conv32_x = ConvBlock(ch_in = 64, ch_out = 128, s = 1, act = act)\n",
        "\n",
        "      self.conv41_x = ConvBlock(ch_in = 128, ch_out = 128, s = 2, act = act)\n",
        "      self.conv42_x = ConvBlock(ch_in = 128, ch_out = 256, s = 1, act = act)\n",
        "\n",
        "      self.conv51_x = ConvBlock(ch_in = 256, ch_out = 256, s = 2, act = act)\n",
        "      self.conv52_x = ConvBlock(ch_in = 256, ch_out = 512, s = 1, act = act)\n",
        "\n",
        "      self.drop = torch.nn.Dropout(p=drop_rate)\n",
        "      self.fc = nn.Linear(512, 1)\n",
        "      self.sg = nn.Sigmoid()\n",
        "\n",
        "      ##### END OF YOUR CODE #####\n",
        "\n",
        "    def forward(self, X):\n",
        "      ##### START OF YOUR CODE #####\n",
        "      \n",
        "      # 256 x 256 x 1\n",
        "      X = self.conv1(X)    # output: 128 x 128 x 64\n",
        "      X = self.batch1(X)   # output: 128 x 128 x 64\n",
        "      X = self.act1(X)     # output: 128 x 128 x 64\n",
        "      X = self.maxpool1(X) # output: 64 x 64 x 64\n",
        "      \n",
        "      X = self.conv21_x(X)  # output: 64 x 64 x 64\n",
        "      X = self.conv22_x(X)  # output: 64 x 64 x 64\n",
        "      \n",
        "      X = self.conv31_x(X)  # output: 32 x 32 x 64\n",
        "      X = self.conv32_x(X)  # output: 32 x 32 x 128\n",
        "    \n",
        "      X = self.conv41_x(X)  # output: 16 x 16 x 128\n",
        "      X = self.conv42_x(X)  # output: 16 x 16 x 256\n",
        "   \n",
        "      X = self.conv51_x(X)  # output: 8 x 8 x 256\n",
        "      X = self.conv52_x(X)  # output: 8 x 8 x 512\n",
        "      \n",
        "      # (B, C, W, H) to (B, C, W * H)  \n",
        "      X = nn.AvgPool2d(X.size(-1))(X)\n",
        "      X = X.view(X.size(0), -1)\n",
        "      X = self.drop(X) # drop out after average pooling.\n",
        "\n",
        "      X = self.fc(X)\n",
        "      X = self.sg(X)\n",
        "      ##### END OF YOUR CODE #####\n",
        "      return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "dvviIPvsSj6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e3f35d-1f70-4c1f-d933-8d3eb7630c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           3,200\n",
            "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
            "              ReLU-3         [-1, 64, 128, 128]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
            "            Conv2d-5           [-1, 64, 64, 64]          36,928\n",
            "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
            "              ReLU-7           [-1, 64, 64, 64]               0\n",
            "            Conv2d-8           [-1, 64, 64, 64]          36,928\n",
            "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
            "           Conv2d-10           [-1, 64, 64, 64]           4,160\n",
            "      BatchNorm2d-11           [-1, 64, 64, 64]             128\n",
            "             ReLU-12           [-1, 64, 64, 64]               0\n",
            "        ConvBlock-13           [-1, 64, 64, 64]               0\n",
            "           Conv2d-14           [-1, 64, 64, 64]          36,928\n",
            "      BatchNorm2d-15           [-1, 64, 64, 64]             128\n",
            "             ReLU-16           [-1, 64, 64, 64]               0\n",
            "           Conv2d-17           [-1, 64, 64, 64]          36,928\n",
            "      BatchNorm2d-18           [-1, 64, 64, 64]             128\n",
            "           Conv2d-19           [-1, 64, 64, 64]           4,160\n",
            "      BatchNorm2d-20           [-1, 64, 64, 64]             128\n",
            "             ReLU-21           [-1, 64, 64, 64]               0\n",
            "        ConvBlock-22           [-1, 64, 64, 64]               0\n",
            "           Conv2d-23           [-1, 64, 32, 32]          36,928\n",
            "      BatchNorm2d-24           [-1, 64, 32, 32]             128\n",
            "             ReLU-25           [-1, 64, 32, 32]               0\n",
            "           Conv2d-26           [-1, 64, 32, 32]          36,928\n",
            "      BatchNorm2d-27           [-1, 64, 32, 32]             128\n",
            "           Conv2d-28           [-1, 64, 32, 32]           4,160\n",
            "      BatchNorm2d-29           [-1, 64, 32, 32]             128\n",
            "             ReLU-30           [-1, 64, 32, 32]               0\n",
            "        ConvBlock-31           [-1, 64, 32, 32]               0\n",
            "           Conv2d-32           [-1, 64, 32, 32]          36,928\n",
            "      BatchNorm2d-33           [-1, 64, 32, 32]             128\n",
            "             ReLU-34           [-1, 64, 32, 32]               0\n",
            "           Conv2d-35          [-1, 128, 32, 32]          73,856\n",
            "      BatchNorm2d-36          [-1, 128, 32, 32]             256\n",
            "           Conv2d-37          [-1, 128, 32, 32]           8,320\n",
            "      BatchNorm2d-38          [-1, 128, 32, 32]             256\n",
            "             ReLU-39          [-1, 128, 32, 32]               0\n",
            "        ConvBlock-40          [-1, 128, 32, 32]               0\n",
            "           Conv2d-41          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-42          [-1, 128, 16, 16]             256\n",
            "             ReLU-43          [-1, 128, 16, 16]               0\n",
            "           Conv2d-44          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-45          [-1, 128, 16, 16]             256\n",
            "           Conv2d-46          [-1, 128, 16, 16]          16,512\n",
            "      BatchNorm2d-47          [-1, 128, 16, 16]             256\n",
            "             ReLU-48          [-1, 128, 16, 16]               0\n",
            "        ConvBlock-49          [-1, 128, 16, 16]               0\n",
            "           Conv2d-50          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-51          [-1, 128, 16, 16]             256\n",
            "             ReLU-52          [-1, 128, 16, 16]               0\n",
            "           Conv2d-53          [-1, 256, 16, 16]         295,168\n",
            "      BatchNorm2d-54          [-1, 256, 16, 16]             512\n",
            "           Conv2d-55          [-1, 256, 16, 16]          33,024\n",
            "      BatchNorm2d-56          [-1, 256, 16, 16]             512\n",
            "             ReLU-57          [-1, 256, 16, 16]               0\n",
            "        ConvBlock-58          [-1, 256, 16, 16]               0\n",
            "           Conv2d-59            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-60            [-1, 256, 8, 8]             512\n",
            "             ReLU-61            [-1, 256, 8, 8]               0\n",
            "           Conv2d-62            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-63            [-1, 256, 8, 8]             512\n",
            "           Conv2d-64            [-1, 256, 8, 8]          65,792\n",
            "      BatchNorm2d-65            [-1, 256, 8, 8]             512\n",
            "             ReLU-66            [-1, 256, 8, 8]               0\n",
            "        ConvBlock-67            [-1, 256, 8, 8]               0\n",
            "           Conv2d-68            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-69            [-1, 256, 8, 8]             512\n",
            "             ReLU-70            [-1, 256, 8, 8]               0\n",
            "           Conv2d-71            [-1, 512, 8, 8]       1,180,160\n",
            "      BatchNorm2d-72            [-1, 512, 8, 8]           1,024\n",
            "           Conv2d-73            [-1, 512, 8, 8]         131,584\n",
            "      BatchNorm2d-74            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-75            [-1, 512, 8, 8]               0\n",
            "        ConvBlock-76            [-1, 512, 8, 8]               0\n",
            "          Dropout-77                  [-1, 512]               0\n",
            "           Linear-78                    [-1, 1]             513\n",
            "          Sigmoid-79                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 4,300,161\n",
            "Trainable params: 4,300,161\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.25\n",
            "Forward/backward pass size (MB): 83.00\n",
            "Params size (MB): 16.40\n",
            "Estimated Total Size (MB): 99.66\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "# Print the summary of model\n",
        "device = torch.device('cuda')\n",
        "model = ResNet18(\"relu\", .5).to(device)\n",
        "summary(model, (1, 256, 256))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-isk7NCKzvlu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}